# AI HANDOFF DOCUMENTATION
## Mention Market Tool - Trump Transcript Scraper & Analysis

**Date:** December 16, 2025
**Previous AI:** Claude Code (Terminal)
**Reason for Handoff:** Terminal interface limitations, scraper reliability issues

---

## ðŸš¨ CRITICAL CURRENT ISSUES

### Issue #1: 78 Missing Transcripts (HIGHEST PRIORITY)
**Problem:** Database has 1109 transcript entries but 78 are missing full content (word_count = 0 or empty full_dialogue)

**Root Cause:**
- These transcripts have titles like "No Transcript" but they DO have actual transcripts on RollCall
- Example: Pennsylvania rally (Dec 9, 2025) was flagged as "No Transcript" but has full content on RollCall
- The scraper is encountering these and skipping them instead of retrying with different selectors

**What needs to happen:**
```sql
-- Check current missing count:
sqlite3 data/transcripts.db "SELECT COUNT(*) FROM transcripts WHERE full_dialogue = '' OR word_count = 0;"

-- List them:
sqlite3 data/transcripts.db "SELECT id, date, title, url FROM transcripts WHERE word_count = 0 ORDER BY date DESC LIMIT 20;"
```

**Action Required:**
1. Get list of all 78 URLs from database
2. Scrape each URL individually with proper error handling
3. Try multiple CSS selectors if first attempt fails
4. DO NOT skip any transcript - they ALL have content
5. Verify Pennsylvania rally specifically: `https://rollcall.com/factbase/trump/transcript/donald-trump-speech-pennsylvania-political-rally-mount-pocono-december-9-2025`

### Issue #2: Date Range Accuracy
**Problem:** October 15 transcript was appearing in December date range (now fixed in database but needs verification)

**Fixed:** Transcript ID 315 corrected from 2025-12-15 to 2025-10-15

**Verify:**
```sql
sqlite3 data/transcripts.db "SELECT date, title FROM transcripts WHERE title LIKE '%October%' AND date NOT LIKE '%-10-%';"
```

### Issue #3: Dot Plot Chart Issues
**Problem:**
- Multiple transcripts per date not showing correctly
- Clicking dots takes you to wrong transcript
- Chart showing transcripts outside selected date range

**Status:** Fixed in `analytics_ui.html` (lines 1220-1294) but needs testing

---

## ðŸ“ PROJECT STRUCTURE

```
Mention Market Tool/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ transcripts.db          # SQLite database (1109 transcripts, 78 incomplete)
â”œâ”€â”€ rollcall_scraper_robust.py  # Main scraper (has issues with "No Transcript" pages)
â”œâ”€â”€ api_server.py               # Flask API serving data
â”œâ”€â”€ analytics_ui.html           # Frontend interface
â”œâ”€â”€ text_analysis.py            # Word frequency analysis
â”œâ”€â”€ missing_urls.txt            # List of 78 incomplete transcript URLs
â””â”€â”€ AI_HANDOFF.md              # This file
```

---

## ðŸŽ¯ USER'S PRIMARY GOAL

**What the user does:** Bets on prediction markets about what Trump will say in speeches

**Why this tool matters:** Needs 100% accurate, complete transcript data from Sept 2024 to present to:
- Search for specific words Trump has said
- See frequency and context of mentions
- Identify patterns in speech topics
- Make informed betting decisions

**Zero tolerance for:**
- Missing transcripts
- Incomplete data
- Inaccurate date ranges
- Broken search functionality

---

## ðŸ—„ï¸ DATABASE SCHEMA

```sql
-- Main table:
CREATE TABLE transcripts (
    id INTEGER PRIMARY KEY,
    title TEXT,
    date TEXT,              -- Format: YYYY-MM-DD
    speech_type TEXT,       -- "Speech", "Interview", "Remarks", etc.
    location TEXT,
    url TEXT UNIQUE,
    full_dialogue TEXT,     -- Complete word-for-word transcript
    word_count INTEGER,
    speakers_json TEXT      -- JSON array of speakers
);

-- Critical queries:
-- Check for missing content:
SELECT COUNT(*) FROM transcripts WHERE full_dialogue = '' OR word_count = 0;

-- Check date range:
SELECT MIN(date), MAX(date), COUNT(*) FROM transcripts;

-- Check for duplicates:
SELECT url, COUNT(*) FROM transcripts GROUP BY url HAVING COUNT(*) > 1;
```

---

## ðŸ¤– SCRAPER ARCHITECTURE

### Main Scraper: `rollcall_scraper_robust.py`

**What it does:**
1. Opens RollCall search page with Selenium
2. Infinite scrolls to collect ALL transcript URLs (Sept 2024 - present)
3. Scrapes each URL for full dialogue text
4. Saves to SQLite database

**Known Issues:**
- Gets stuck on "No Transcript" pages instead of trying harder
- Needs better CSS selector fallback logic
- Should retry failed scrapes 3-5 times with different approaches

**Current selectors (in order of priority):**
```python
# Try these in order:
1. div.transcript-content
2. div.transcript-text
3. article
4. div[class*="transcript"]
5. main
```

### API Server: `api_server.py`

**Endpoints:**
- `GET /api/transcripts` - Returns all transcripts with full dialogue
- `POST /api/scraper/refresh` - Triggers scraper (currently broken)
- `GET /api/scraper/status` - Check scraper status

**Current status:** Running on port 5001

---

## ðŸŽ¨ FRONTEND: `analytics_ui.html`

**Features:**
1. Search for words in Trump's dialogue only (not other speakers)
2. Dot plot chart showing mentions over time
3. Location chart (where in speech Trump says words)
4. Full transcript viewer with search terms in **bold blue**
5. Filters: date range, speech type, speakers, minimum word count

**Recent Changes:**
- Search terms now shown as **bold blue text** (not highlighted)
- Fixed chart to show ALL dates in range (not just ones with mentions)
- Fixed multiple transcripts per date handling
- Added minimum word count filter (default: 500 words)

**Known Issues:**
- Blue progress bar navigation might not work correctly
- Search highlighting was buggy, switched to bold blue text
- Need to verify chart clicks go to correct transcript

---

## ðŸ”§ HOW TO FIX THE MISSING TRANSCRIPTS

### Approach 1: Individual URL Scraping (RECOMMENDED)

Create a new script `fix_missing_transcripts.py`:

```python
#!/usr/bin/env python3
"""
Scrape the 78 missing transcripts one by one
"""
import sqlite3
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time

def get_missing_urls():
    conn = sqlite3.connect('data/transcripts.db')
    cursor = conn.cursor()
    cursor.execute("SELECT id, url FROM transcripts WHERE word_count = 0 OR full_dialogue = ''")
    return cursor.fetchall()

def scrape_single(transcript_id, url):
    options = Options()
    options.add_argument('--headless')
    driver = webdriver.Chrome(options=options)

    try:
        driver.get(url)
        time.sleep(3)

        # Try multiple selectors
        selectors = [
            'div.transcript-content',
            'div.transcript-text',
            'article',
            'div[class*="transcript"]',
            'main'
        ]

        dialogue = None
        for selector in selectors:
            try:
                elem = driver.find_element(By.CSS_SELECTOR, selector)
                paragraphs = elem.find_elements(By.TAG_NAME, 'p')
                lines = [p.text.strip() for p in paragraphs if p.text.strip()]
                if len(lines) > 5:  # Must have at least 5 paragraphs
                    dialogue = '\n'.join(lines)
                    break
            except:
                continue

        if dialogue and len(dialogue) > 500:
            # Save to database
            conn = sqlite3.connect('data/transcripts.db')
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE transcripts
                SET full_dialogue = ?, word_count = ?
                WHERE id = ?
            """, (dialogue, len(dialogue.split()), transcript_id))
            conn.commit()
            conn.close()
            return True

        return False

    finally:
        driver.quit()

# Main execution
missing = get_missing_urls()
print(f"Found {len(missing)} missing transcripts")

success = 0
failed = []

for i, (transcript_id, url) in enumerate(missing, 1):
    print(f"[{i}/{len(missing)}] Scraping ID {transcript_id}...")
    if scrape_single(transcript_id, url):
        success += 1
        print(f"  âœ“ Success")
    else:
        failed.append((transcript_id, url))
        print(f"  âœ— Failed")

    time.sleep(2)  # Rate limiting

print(f"\nResults: {success} success, {len(failed)} failed")
if failed:
    print("\nFailed URLs:")
    for tid, url in failed:
        print(f"  {tid}: {url}")
```

### Approach 2: Fix the Main Scraper

Edit `rollcall_scraper_robust.py` around line 150-200 where it scrapes dialogue:

**Problem section:**
```python
if not dialogue_found:
    print("  âš ï¸  No dialogue found - Retrying...")
    # CURRENTLY GIVES UP TOO EASILY
```

**Fix it to:**
```python
if not dialogue_found:
    # Try alternative selectors
    alternative_selectors = [
        'div[class*="transcript"]',
        'main',
        'body'  # Last resort
    ]
    for alt_selector in alternative_selectors:
        try:
            element = driver.find_element(By.CSS_SELECTOR, alt_selector)
            # ... try to extract text
        except:
            continue
```

---

## ðŸ“‹ IMMEDIATE ACTION ITEMS

**Priority Order:**

1. âœ… **Verify database state**
   ```bash
   sqlite3 data/transcripts.db "SELECT COUNT(*) FROM transcripts WHERE word_count > 0;"
   sqlite3 data/transcripts.db "SELECT COUNT(*) FROM transcripts WHERE word_count = 0;"
   ```

2. ðŸš¨ **Fix the 78 missing transcripts** (USE APPROACH 1 ABOVE)
   - Pennsylvania rally is ID 1765 - verify this one specifically
   - Run the fix_missing_transcripts.py script
   - Should take 15-30 minutes

3. âœ… **Verify all transcripts Sept 2024 - Dec 2025**
   ```bash
   sqlite3 data/transcripts.db "SELECT MIN(date), MAX(date) FROM transcripts WHERE word_count > 0;"
   ```

4. ðŸ§ª **Test the frontend**
   - Search for "Pennsylvania" - should return Dec 9 rally
   - Search for "autopen" - should show multiple results in Dec 2025
   - Verify date filters work correctly
   - Check dot plot chart shows correct transcripts

5. ðŸ”„ **Fix sync button**
   - Currently the `/api/scraper/refresh` endpoint works but takes too long
   - Consider running scraper incrementally (check for new transcripts daily)

---

## ðŸŽ¯ USER REQUIREMENTS & PREFERENCES

**Communication Style:**
- User is direct and results-focused
- Zero tolerance for excuses or assumptions
- If user shows a screenshot, they are RIGHT - don't argue
- "I need 100% accuracy" means LITERALLY 100%, not 99.9%

**Technical Priorities:**
1. Data accuracy above all else
2. Complete transcripts (no missing content)
3. Fast search functionality
4. Clean, simple UI

**What NOT to do:**
- Don't assume transcripts are "unavailable" without checking
- Don't skip transcripts marked "No Transcript" - they have content
- Don't make excuses about RollCall's structure - just scrape it
- Don't over-engineer solutions - simple and working beats complex

---

## ðŸ” DEBUGGING COMMANDS

```bash
# Check API server status
curl http://localhost:5001/api/stats

# Count transcripts by type
sqlite3 data/transcripts.db "SELECT speech_type, COUNT(*) FROM transcripts GROUP BY speech_type;"

# Find specific transcript
sqlite3 data/transcripts.db "SELECT * FROM transcripts WHERE title LIKE '%Pennsylvania%' AND date = '2025-12-09';"

# Check for date anomalies
sqlite3 data/transcripts.db "SELECT date, COUNT(*) FROM transcripts GROUP BY date HAVING COUNT(*) > 3;"

# List recent transcripts
sqlite3 data/transcripts.db "SELECT date, title FROM transcripts WHERE date >= '2025-12-01' ORDER BY date DESC;"

# Export missing URLs
sqlite3 data/transcripts.db "SELECT url FROM transcripts WHERE word_count = 0;" > missing_urls.txt

# Check total words across all transcripts
sqlite3 data/transcripts.db "SELECT SUM(word_count) FROM transcripts WHERE word_count > 0;"
```

---

## ðŸ’¡ QUICK WINS FOR NEW AI

1. **Run the fix_missing_transcripts.py script above** - This will immediately solve the biggest issue

2. **Add better logging** to scraper:
   ```python
   import logging
   logging.basicConfig(filename='scraper.log', level=logging.DEBUG)
   ```

3. **Add retry logic** everywhere:
   ```python
   from tenacity import retry, stop_after_attempt, wait_fixed

   @retry(stop=stop_after_attempt(3), wait=wait_fixed(5))
   def scrape_url(url):
       # ... scraping code
   ```

4. **Create a verification script** that runs after every scrape:
   ```python
   # verify_data.py
   conn = sqlite3.connect('data/transcripts.db')
   cursor = conn.cursor()

   # Check 1: No missing content
   cursor.execute("SELECT COUNT(*) FROM transcripts WHERE word_count = 0")
   missing = cursor.fetchone()[0]
   assert missing == 0, f"Found {missing} transcripts with no content!"

   # Check 2: Date range coverage
   cursor.execute("SELECT MIN(date), MAX(date) FROM transcripts")
   min_date, max_date = cursor.fetchone()
   assert min_date == '2024-09-03', f"Missing early transcripts! Starts at {min_date}"

   print("âœ… All checks passed!")
   ```

---

## ðŸ“ž HANDOFF CHECKLIST

Before considering this transition complete:

- [ ] All 78 missing transcripts scraped successfully
- [ ] Pennsylvania rally (Dec 9, 2025) has full content
- [ ] Date range is Sept 3, 2024 to current date with no gaps
- [ ] Frontend search works for "Pennsylvania", "autopen", "hottest"
- [ ] Dot plot chart shows correct data and links to correct transcripts
- [ ] API server running and responsive
- [ ] Sync button works (or disabled if not working)
- [ ] User can search, filter, and view full transcripts without errors

---

## ðŸš€ RECOMMENDED FIRST PROMPT FOR NEW AI

When you open this project in Cursor/VS Code, use this prompt:

```
I need you to take over this Trump transcript scraping project. Previous AI was using Claude Code terminal which had limitations.

CRITICAL ISSUE: Database has 78 transcripts with missing content (word_count = 0). These are marked "No Transcript" but they DO have transcripts on RollCall. The Pennsylvania rally from Dec 9, 2025 is one example - it exists but wasn't scraped.

Read AI_HANDOFF.md fully - it has complete context.

Your first task: Create and run fix_missing_transcripts.py to scrape all 78 missing transcripts. Use Selenium with multiple CSS selector fallbacks. Do NOT skip any transcript.

After that's done, verify:
1. Pennsylvania rally has content
2. All transcripts from Sept 2024 to present are complete
3. Frontend search and charts work correctly

Be direct, don't make excuses, and get 100% of transcripts scraped.
```

---

## ðŸŽ“ LESSONS LEARNED

**What went wrong with terminal AI:**
1. Long-running processes (scraper) were hard to monitor
2. No easy way to inspect HTML/debug CSS selectors
3. Background tasks would hang or timeout
4. Hard to switch between files quickly

**What would have helped:**
- Visual file tree to see all code at once
- Integrated browser for testing scraper output
- Better process management for long-running scrapers
- Debugger for stepping through scraper code

**For next AI:**
- Use Cursor's file tree to see all code
- Test scraper on single URLs first before batch
- Add extensive logging to scraper
- Create test suite to verify data quality
- Set up automatic daily scraper runs

---

## ðŸ“š ADDITIONAL RESOURCES

- RollCall base URL: `https://rollcall.com/factbase/trump`
- Database path: `./data/transcripts.db`
- API runs on: `http://localhost:5001`
- Frontend opens: `analytics_ui.html` (open in browser)

**Python dependencies:**
```bash
pip3 install selenium beautifulsoup4 flask flask-cors requests
```

**Chrome driver:**
```bash
# Should already be installed, but if needed:
brew install chromedriver
```

---

**END OF HANDOFF DOCUMENT**

*Good luck! The user needs this working 100% for their betting business. No excuses, no assumptions - just get all the transcripts scraped.*
